---
title: "Generating Reproducible Statistical Analyses and Evaluation Reports:
        Principles, Practices, and Free Software Tools"
subtitle: "Demonstration at *Evaluation 2024: Amplifying and Empowering 
           Voices*, annual conference of the American Evaluation Association, 
           Portland, OR"
author: "Steven J. Pierce"
institute: "Center for Statistical Training and Consulting, Michigan State University"
date: October 22, 2024
format: 
  revealjs:
    embed-resources: true
    theme: CSTAT_theme.scss
    css: CSTAT_style.css
    slide-number: c/t
    show-notes: true
    footer: <a href="https://github.com/sjpierce/Pierce.AEA2024">https://github.com/sjpierce/Pierce.AEA2024</a>
    logo: graphics/CSTATLogoH.png
    link-external-icon: true
    link-external-newwindow: true
---

# Section 1

## Reproducibility

Definition

## Requirements for Reproducibility

* Data
* Code
* Software 

## Benefits of Reproducibility

* Accuracy
* Efficiency
* Credibility

## Manual Workflow

## Reproducible Workflow

* Eliminate manual steps!
* Produce fully-formatted, publication-quality reports:
    * Narrative text, headings
    * Software code (optional)
    * Dynamically inserted statistical results
    * Dynamic tables
    * Dynamic figures 
    * Dynamic reference sections

## Version Control 
